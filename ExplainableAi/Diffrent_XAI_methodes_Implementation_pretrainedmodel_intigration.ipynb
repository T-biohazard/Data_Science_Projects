{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgXb1pE1RuBE",
        "outputId": "fae51885-56c1-4edf-a3d4-f5c414f53fa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch-grad-cam (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch-grad-cam\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torchvision torch pytorch-grad-cam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G3ALUFFs6nK",
        "outputId": "6d502b64-a856-496b-f47b-dfff1f7b9ccc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grad-cam\n",
            "  Downloading grad-cam-1.5.3.tar.gz (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from grad-cam) (10.4.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.19.1+cu121)\n",
            "Collecting ttach (from grad-cam)\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.66.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from grad-cam) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.5.3-py3-none-any.whl size=38657 sha256=2b90ca715964067cffb1295c46603328061d0f75a12beb24d952b0f8289b3974\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/ce/70/fe64f851895eae830b3c63ec7fc464cfa7c81aeb7ad4f68063\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.5.3 ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_grad_cam import GradCAM # this should now work\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget"
      ],
      "metadata": {
        "id": "hmK4G1vPR1pM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZgLDm8tr2IX",
        "outputId": "829d8184-35c5-441e-a946-e5cfd6d6a51b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your dataset (replace with your actual path in Google Drive)\n",
        "img_folder = '/content/drive/MyDrive/mpox/'\n",
        "infected_folder = img_folder + 'Monkeypox/'\n",
        "non_infected_folder = img_folder + 'Others/' #Fixed typo: changed 'non_infected' to 'non-infected'\n"
      ],
      "metadata": {
        "id": "tSjRvKver28o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "img_paths = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "gVrGYbLvr6G4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have two folders 'infected' and 'non_infected'\n",
        "# Collect infected images\n",
        "for img_name in os.listdir(infected_folder):\n",
        "    img_paths.append(os.path.join(infected_folder, img_name))\n",
        "    labels.append(1)  # Label 1 for infected"
      ],
      "metadata": {
        "id": "KDA_CH3or6sS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect non-infected images\n",
        "for img_name in os.listdir(non_infected_folder):\n",
        "    img_paths.append(os.path.join(non_infected_folder, img_name))\n",
        "    labels.append(0)  # Label 0 for non-infected"
      ],
      "metadata": {
        "id": "wtR9w-k1sJQo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MedicalDataset class\n",
        "class MedicalDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB') # Ensure the image is loaded as RGB\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "EAZRVUjbR5OK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "Pe6jDs1esVgp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and dataloader\n",
        "dataset = MedicalDataset(img_paths, labels, transform=transform)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "8jo_tTXbsbI5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained EfficientNetV2-S model\n",
        "model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
        "\n",
        "# Replace the classifier layer to fit your number of classes\n",
        "# Assuming binary classification (infected vs non-infected)\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, 2)  # 2 classes for binary classification\n",
        "\n",
        "# Move the model to the appropriate device (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "yvwTV9DuR79i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb449f7-b6ef-4064-f8c0-7142f34ad6eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 150MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 25  # Adjust based on your dataset\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in data_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(data_loader)}')\n"
      ],
      "metadata": {
        "id": "TmTlRVvNSCzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# Assuming 'model' is your loaded EfficientNetV2-S model\n",
        "\n",
        "# Target the last InvertedResidual block within the 'features' module\n",
        "target_layers = [model.features[-1]]  # This selects the last layer in features, which is usually the last block\n",
        "\n",
        "# ... (rest of your Grad-CAM code)\n",
        "cam = GradCAM(model=model, target_layers=target_layers) #Remove use_cuda argument!pip install grad-cam\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# Assuming 'model' is your loaded EfficientNetV2-S model\n",
        "\n",
        "# Target the last InvertedResidual block within the 'features' module\n",
        "target_layers = [model.features[-1]]  # This selects the last layer in features, which is usually the last block\n",
        "\n",
        "# ... (rest of your Grad-CAM code)\n",
        "cam = GradCAM(model=model, target_layers=target_layers) #Remove use_cuda argument"
      ],
      "metadata": {
        "id": "gpXOl4h7nUP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on a new image\n",
        "image_path = '/content/drive/MyDrive/mpox/Monkeypox/IMG_20211108_120232 (Custom).jpg'  # Your test image\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "pUrQMQvnuPw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate CAM\n",
        "targets = [ClassifierOutputTarget(1)]  # Assuming label 1 corresponds to 'infected'\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n"
      ],
      "metadata": {
        "id": "6pYbSQVJuRV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the original image to match the CAM dimensions\n",
        "img = img.resize((224, 224))\n",
        "img_np = np.array(img) / 255.0  # Normalize pixel values to the range [0, 1]\n",
        "\n",
        "# Ensure img_np is of type float32\n",
        "img_np = img_np.astype(np.float32)  # Convert to float32\n",
        "\n",
        "# Ensure grayscale_cam is a 2D array\n",
        "grayscale_cam = grayscale_cam[0, :]  # Assuming grayscale_cam has shape (1, 224, 224)\n",
        "\n",
        "# Generate CAM\n",
        "# ... your existing code ...\n",
        "cam_image = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)"
      ],
      "metadata": {
        "id": "1AQk2tYzngsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the result\n",
        "plt.imshow(cam_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2A7PZlIluT8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Display the original image and the Grad-CAM overlay\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(img_np) # Changed image_np to img_np\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Grad-CAM')\n",
        "plt.imshow(cam_image)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DZrPH5zkbAhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying on diffrent data sample _ Infected"
      ],
      "metadata": {
        "id": "gsZzkymbzmwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on a new image\n",
        "image_path = '/content/drive/MyDrive/mpox/Monkeypox/IMG_20211108_120232 (Custom).jpg'  # Your test image\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "input_tensor = transform(img).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "w4sqA4J6y9Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate CAM\n",
        "targets = [ClassifierOutputTarget(1)]  # Assuming label 1 corresponds to 'infected'\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "# Resize the original image to match the CAM dimensions\n",
        "img = img.resize((224, 224))\n",
        "img_np = np.array(img) / 255.0\n",
        "\n",
        "# Ensure grayscale_cam has the correct number of channels\n",
        "if len(grayscale_cam.shape) == 2:\n",
        "    grayscale_cam = grayscale_cam[..., np.newaxis]"
      ],
      "metadata": {
        "id": "TyER5tl9y9Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate CAM\n",
        "cam_image = show_cam_on_image(img_np, grayscale_cam[0, :], use_rgb=True)\n",
        "\n",
        "# 8. Display the original image and the Grad-CAM overlay\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(img_np)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Grad-CAM')\n",
        "plt.imshow(cam_image)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HJ7Bki6Ly9Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying on diffrent data sample _ Infected"
      ],
      "metadata": {
        "id": "4UD8dN2uzboY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on a new image\n",
        "image_path = '/content/drive/MyDrive/mpox/Monkeypox/IMG_20211108_120232 (Custom).jpg'  # Your test image\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "# Generate CAM\n",
        "targets = [ClassifierOutputTarget(1)]  # Assuming label 1 corresponds to 'infected'\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "# Resize the original image to match the CAM dimensions\n",
        "img = img.resize((224, 224))\n",
        "img_np = np.array(img) / 255.0\n",
        "\n",
        "# Ensure grayscale_cam has the correct number of channels\n",
        "if len(grayscale_cam.shape) == 2:\n",
        "    grayscale_cam = grayscale_cam[..., np.newaxis]\n",
        "\n",
        "# Generate CAM\n",
        "cam_image = show_cam_on_image(img_np, grayscale_cam[0, :], use_rgb=True)\n",
        "\n",
        "# 8. Display the original image and the Grad-CAM overlay\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(img_np)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Grad-CAM')\n",
        "plt.imshow(cam_image)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1m4QSCH-zVBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ScoreCAM\n"
      ],
      "metadata": {
        "id": "3GKgOYhP_fHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-gradcam\n",
        "\n",
        "from pytorch_grad_cam import ScoreCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... your existing code for model loading, transform, and device ...\n",
        "\n",
        "# Test the model on a new image\n",
        "image_path = '/content/drive/MyDrive/mpox/Monkeypox/IMG_20211108_120232 (Custom).jpg'  # Your test image\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "# Initialize Score-CAM\n",
        "cam = ScoreCAM(model=model, target_layers=target_layers) # Replace model and target_layers\n",
        "\n",
        "# Generate CAM\n",
        "targets = [ClassifierOutputTarget(1)]  # Assuming label 1 corresponds to 'infected'\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "# Resize the original image to match the CAM dimensions\n",
        "img = img.resize((224, 224))\n",
        "img_np = np.array(img) / 255.0\n",
        "\n",
        "# Ensure grayscale_cam has the correct number of channels\n",
        "if len(grayscale_cam.shape) == 2:\n",
        "    grayscale_cam = grayscale_cam[..., np.newaxis]\n",
        "\n",
        "# Generate CAM\n",
        "cam_image = show_cam_on_image(img_np, grayscale_cam[0, :], use_rgb=True)\n",
        "\n",
        "# Display the original image and the Score-CAM overlay\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(img_np)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Score-CAM')\n",
        "plt.imshow(cam_image)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o9yPKKVp0mC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-gradcam\n",
        "\n",
        "from pytorch_grad_cam import ScoreCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... your existing code for model loading, transform, and device ...\n",
        "\n",
        "# Test the model on a new image\n",
        "image_path = '/content/drive/MyDrive/mpox/Monkeypox/M01_01_00.jpg'  # Your test image\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "# Initialize Score-CAM\n",
        "cam = ScoreCAM(model=model, target_layers=target_layers) # Replace model and target_layers\n",
        "\n",
        "# Generate CAM\n",
        "targets = [ClassifierOutputTarget(1)]  # Assuming label 1 corresponds to 'infected'\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "# Resize the original image to match the CAM dimensions\n",
        "img = img.resize((224, 224))\n",
        "img_np = np.array(img) / 255.0\n",
        "\n",
        "# Ensure grayscale_cam has the correct number of channels\n",
        "if len(grayscale_cam.shape) == 2:\n",
        "    grayscale_cam = grayscale_cam[..., np.newaxis]\n",
        "\n",
        "# Generate CAM\n",
        "cam_image = show_cam_on_image(img_np, grayscale_cam[0, :], use_rgb=True)\n",
        "\n",
        "# Display the original image and the Score-CAM overlay\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(img_np)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Score-CAM')\n",
        "plt.imshow(cam_image)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ME37h6EubgUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GradCAMPlusPlus"
      ],
      "metadata": {
        "id": "QENoxzuM_q_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-gradcam\n",
        "\n",
        "from pytorch_grad_cam import GradCAMPlusPlus\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... your existing code for model loading, transform, and device ...\n",
        "\n",
        "# Test the model on a new image\n",
        "image_path = '/content/drive/MyDrive/mpox/Monkeypox/M04_01_00.jpg'\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "# Initialize GradCAM++\n",
        "cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
        "\n",
        "# Generate CAM\n",
        "targets = [ClassifierOutputTarget(1)]\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "# ... (Resize, handle channels, and visualize as in the previous example) ...\n",
        "# Display the original\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Original Image')\n",
        "plt.imshow(img_np)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Gradcam++')\n",
        "plt.imshow(cam_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rvbKjaA41GUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VilEvGUj6d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CUXJ2QxSj5ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u9wm-mg0j5fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5NaM_1ySj5Wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8mIztHRUj5Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "189xhq9Fj5MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGradCAM"
      ],
      "metadata": {
        "id": "idwVt4sz_vDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EigenCAM"
      ],
      "metadata": {
        "id": "1kApDb4Q_yaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LayerCAM"
      ],
      "metadata": {
        "id": "b1RBf6lS_3jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Full-Gradient /  FullGrad"
      ],
      "metadata": {
        "id": "nNYUhqSx5zLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Thresholded CAM (Binary Mask)\n",
        "You can apply a threshold to the heatmap after generating it, converting the values into a binary mask (0/1). This highlights only the most activated regions."
      ],
      "metadata": {
        "id": "pSRhoyd36vFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OcclusionSensitivity"
      ],
      "metadata": {
        "id": "Jcd7LqaeACkD"
      }
    }
  ]
}